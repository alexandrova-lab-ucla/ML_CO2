{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib, argparse, uuid, sigopt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit import DataStructs\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from utils.sklearn_utils import *\n",
    "from utils.selfies_util import *\n",
    "\n",
    "import selfies as sf\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers,regularizers\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        print(e)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santiagovargas/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/santiagovargas/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/santiagovargas/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/santiagovargas/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/santiagovargas/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/santiagovargas/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/santiagovargas/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/rdkit/Chem/PandasTools.py\", line 131, in <module>\n",
      "    if 'display.width' in pd.core.config._registered_options:\n",
      "AttributeError: module 'pandas.core' has no attribute 'config'\n"
     ]
    }
   ],
   "source": [
    "#from spektral.layers import GraphAttention, GlobalAttentionPool\n",
    "from spektral.data import BatchLoader, Graph, Dataset, Loader, utils, DisjointLoader, MixedLoader, SingleLoader\n",
    "from spektral.utils import label_to_one_hot, load_sdf, load_csv\n",
    "from spektral.layers.ops import sp_matrix_to_sp_tensor\n",
    "\n",
    "from spektral.datasets import QM9\n",
    "from spektral.data import Dataset, Graph\n",
    "from spektral.utils import label_to_one_hot, sparse\n",
    "from spektral.layers import AGNNConv, ECCConv, GlobalSumPool, GATConv, GeneralConv, GlobalAttentionPool\n",
    "from spektral.models import GeneralGNN, GCN\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "from tensorflow.keras.utils import get_file \n",
    "from rdkit.Chem import PandasTools, SDMolSupplier, Descriptors\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, scale\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names, ret, homo, homo1, diff = sdf()\n",
    "ATOM_TYPES = [1, 6, 7, 8, 9, 17, 35]\n",
    "BOND_TYPES = [1, 2, 3]\n",
    "\n",
    "def atom_to_feature(atom):\n",
    "    \n",
    "        \n",
    "    atomic_num = label_to_one_hot(atom[\"atomic_num\"], ATOM_TYPES)\n",
    "    coords = atom[\"coords\"]\n",
    "    charge = atom[\"charge\"]\n",
    "    iso = atom[\"iso\"]\n",
    "    return np.concatenate((atomic_num, coords, [charge, iso]), -1)\n",
    "\n",
    "def mol_to_adj(mol):\n",
    "    \n",
    "    row, col, edge_features = [], [], []\n",
    "    for bond in mol[\"bonds\"]:\n",
    "        start, end = bond[\"start_atom\"], bond[\"end_atom\"]\n",
    "        row += [start, end]\n",
    "        col += [end, start]\n",
    "        edge_features += [bond[\"type\"]] * 2\n",
    "\n",
    "    a, e = sparse.edge_index_to_matrix(\n",
    "        edge_index=np.array((row, col)).T,\n",
    "        edge_weight=np.ones_like(row),\n",
    "        edge_features=label_to_one_hot(edge_features, BOND_TYPES),\n",
    "    )\n",
    "    return a, e\n",
    "\n",
    "def read_mol(mol):\n",
    "    x = np.array([atom_to_feature(atom) for atom in mol[\"atoms\"]])\n",
    "    a, e = mol_to_adj(mol)\n",
    "    return x, a, e\n",
    "\n",
    "\n",
    "\n",
    "def parse_sdf(sdf):\n",
    "    #print(sdf)\n",
    "    sdf_out = {}\n",
    "    sdf = sdf.split(\"\\n\")\n",
    "    sdf_out[\"name\"], sdf_out[\"details\"], sdf_out[\"comment\"] = _parse_header(sdf)\n",
    "    sdf_out[\"n_atoms\"], sdf_out[\"n_bonds\"] = _parse_counts_line(sdf)\n",
    "    sdf_out[\"atoms\"] = _parse_atoms_block(sdf, sdf_out[\"n_atoms\"])\n",
    "    sdf_out[\"bonds\"] = _parse_bonds_block(sdf, sdf_out[\"n_atoms\"], sdf_out[\"n_bonds\"])\n",
    "    sdf_out[\"properties\"] = _parse_properties(\n",
    "        sdf, sdf_out[\"n_atoms\"], sdf_out[\"n_bonds\"]\n",
    "    )\n",
    "    sdf_out[\"data\"] = _parse_data_fields(sdf)\n",
    "    return sdf_out\n",
    "\n",
    "def parse_sdf_file(sdf_file, amount=None):\n",
    "    data = sdf_file.read().split(\"$$$$\\n\")\n",
    "    if data[-1] == \"\":\n",
    "        data = data[:-1]\n",
    "    if amount is not None:\n",
    "        data = data[:amount]\n",
    "    output = [parse_sdf(sdf) for sdf in data]  # Parallel execution doesn't help\n",
    "    return output\n",
    "\n",
    "from spektral.utils.io import *\n",
    "\n",
    "def load_sdf(filename, amount=None):\n",
    "    \"\"\"\n",
    "    Load an .sdf file and return a list of molecules in the internal SDF format.\n",
    "    :param filename: target SDF file\n",
    "    :param amount: only load the first `amount` molecules from the file\n",
    "    :return: a list of molecules in the internal SDF format (see documentation).\n",
    "    \"\"\"\n",
    "    #print(\"Reading SDF\")\n",
    "    with open(filename) as f:\n",
    "        return parse_sdf_file(f, amount=amount)\n",
    "\n",
    "\n",
    "\n",
    "class dataset(Dataset):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def read(self):\n",
    "        \n",
    "        names, ret, homo, homo1, diff = sdf()\n",
    "        mean = np.mean(diff)\n",
    "        std = np.std(diff)\n",
    "        diff_scale = (diff - mean) / std\n",
    "        \n",
    "        data = [parse_sdf(i) for i in ret]\n",
    "        data = Parallel(n_jobs=-1)(delayed(read_mol)(mol) for mol in tqdm(data, ncols=80))\n",
    "        x_list, a_list, e_list = list(zip(*data))\n",
    "        \n",
    "        dataset = [Graph(x=x, a=a, e=e, y = y) for x, a, e, y \n",
    "                   in zip(x_list, a_list, e_list, diff_scale)]\n",
    "\n",
    "        return dataset\n",
    "\n",
    "graph_dataset = dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5fbfe2181cda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlatent_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0minput_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mSampling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m\"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'graph_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-77d416434823>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m################################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# PARAMETERS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m################################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-3\u001b[0m  \u001b[0;31m# Learning rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'graph_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "dataset = graph_dataset\n",
    "################################################################################\n",
    "# PARAMETERS\n",
    "################################################################################\n",
    "learning_rate = 1e-3  # Learning rate\n",
    "epochs = 20  # Number of training epochs\n",
    "batch_size = 1 # Batch size\n",
    "################################################################################\n",
    "# LOAD DATA\n",
    "################################################################################\n",
    "# Train/test split\n",
    "idxs = np.random.permutation(len(dataset))\n",
    "split = int(0.8 * len(dataset))\n",
    "idx_tr, idx_te = np.split(idxs, [split])\n",
    "idx_tr = [int(i) for i in idx_tr]\n",
    "idx_te = [int(i) for i in idx_te]\n",
    "dataset_train = dataset[idx_tr]  \n",
    "dataset_test = dataset[idx_te] \n",
    "steps_per_epoch = len(dataset_tr) /  batch_size\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# Parameters\n",
    "F = dataset.n_node_features  # Dimension of node features\n",
    "S = dataset.n_edge_features  # Dimension of edge features\n",
    "n_out = dataset.n_labels     # Dimension of the target\n",
    "\n",
    "X_in = Input(shape=(None, F))\n",
    "A_in = Input(shape=(None, None))\n",
    "E_in = Input(shape=(None, None, S))\n",
    "\n",
    "X_1 = ECCConv(256, activation=\"relu\")([X_in, A_in, E_in])\n",
    "X_2 = ECCConv(256, activation=\"relu\")([X_1, A_in, E_in])\n",
    "X_3 = GlobalSumPool()(X_2)\n",
    "output = Dense(n_out)(X_3)\n",
    "\n",
    "model = Model(inputs=[X_in, A_in, E_in], outputs=output)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "#encode = GeneralConv(256, dropout=0.2)([])\n",
    "#encode = Dense(n_out)(encode)\n",
    "#encode = GeneralConv(256, dropout=0.2)([])\n",
    "                      \n",
    "\n",
    "GeneralConv(256, dropout=0.2)()\n",
    "\n",
    "\n",
    "n_out = 1\n",
    "\n",
    "steps_per_epoch = len(dataset) /  batch_size\n",
    "loader = BatchLoader(dataset, epochs = epochs, batch_size = batch_size)\n",
    "\n",
    "steps_per_epoch = len(dataset_tr) /  batch_size\n",
    "loader_train = BatchLoader(dataset_train, epochs = epochs, batch_size = batch_size)\n",
    "\n",
    "steps_per_epoch = len(dataset_te) /  batch_size\n",
    "loader_test = BatchLoader(dataset_test, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = 8 #dataset.n_node_features  # Dimension of node features\n",
    "S = 5 #dataset.n_edge_features  # Dimension of edge features\n",
    "n_out = 1     # Dimension of the target\n",
    "\n",
    "X_in = Input(shape=(None, F))\n",
    "A_in = Input(shape=(None, None))\n",
    "E_in = Input(shape=(None, None, S))\n",
    "\n",
    "X_1 = ECCConv(256, activation=\"relu\")([X_in, A_in, E_in])\n",
    "X_2 = ECCConv(256, activation=\"relu\")([X_1, A_in, E_in])\n",
    "output = Dense(n_out)(X_2)\n",
    "\n",
    "model = Model(inputs=[X_in, A_in, E_in], outputs=output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
