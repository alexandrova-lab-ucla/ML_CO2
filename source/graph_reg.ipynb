{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib, argparse, uuid, sigopt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit import DataStructs\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from utils.sklearn_utils import *\n",
    "from utils.selfies_util import *\n",
    "\n",
    "import selfies as sf\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers,regularizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        print(e)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santiagovargas/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/santiagovargas/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/santiagovargas/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/santiagovargas/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/santiagovargas/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/santiagovargas/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/santiagovargas/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/rdkit/Chem/PandasTools.py\", line 131, in <module>\n",
      "    if 'display.width' in pd.core.config._registered_options:\n",
      "AttributeError: module 'pandas.core' has no attribute 'config'\n"
     ]
    }
   ],
   "source": [
    "#from spektral.layers import GraphAttention, GlobalAttentionPool\n",
    "from spektral.data import BatchLoader, Graph, Dataset, Loader, utils, DisjointLoader, MixedLoader, SingleLoader\n",
    "from spektral.utils import label_to_one_hot, load_sdf, load_csv\n",
    "from spektral.layers.ops import sp_matrix_to_sp_tensor\n",
    "\n",
    "from spektral.datasets import QM9\n",
    "from spektral.data import Dataset, Graph\n",
    "from spektral.utils import label_to_one_hot, sparse\n",
    "from spektral.layers import AGNNConv, ECCConv, GlobalSumPool,DiffusionConv, GATConv, GeneralConv, GlobalAttentionPool, GCNConv,CrystalConv, MessagePassing, MinCutPool\n",
    "\n",
    "from spektral.models import GeneralGNN, GCN\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "from tensorflow.keras.utils import get_file \n",
    "from rdkit.Chem import PandasTools, SDMolSupplier, Descriptors\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, scale\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........converting xyz to smiles.......\n",
      " 3007 /61492"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9975 /61492"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 18523 /61492"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 25450 /61492"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 32485 /61492"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 39274 /61492"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 46328 /61492"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 53324 /61492"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 58310 /61492"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1466 /636782"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5499 /63678"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9420 /63678"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 13232 /63678"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2420 / 61182"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10263 / 61182"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 18127 / 61182"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 21781 / 61182"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 25457 / 61182"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 29345 / 61182"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 33176 / 61182"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40763 / 61182"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 44397 / 61182"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50529 / 61182"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 54207 / 61182"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 58089 / 61182"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 61181 / 61182\n",
      "\n",
      "smiles length: 61180\n",
      "\n",
      "\n",
      " 61178 /6118058183\n",
      "58183\n",
      "58183\n",
      "58183\n",
      "58183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 58183/58183 [03:12<00:00, 301.91it/s]\n"
     ]
    }
   ],
   "source": [
    "ATOM_TYPES = [1, 6, 7, 8, 9, 17, 35]\n",
    "BOND_TYPES = [1, 2, 3]\n",
    "\n",
    "def atom_to_feature(atom):\n",
    "    \n",
    "        \n",
    "    atomic_num = label_to_one_hot(atom[\"atomic_num\"], ATOM_TYPES)\n",
    "    coords = atom[\"coords\"]\n",
    "    charge = atom[\"charge\"]\n",
    "    iso = atom[\"iso\"]\n",
    "    return np.concatenate((atomic_num, coords, [charge, iso]), -1)\n",
    "\n",
    "def mol_to_adj(mol):\n",
    "    \n",
    "    row, col, edge_features = [], [], []\n",
    "    for bond in mol[\"bonds\"]:\n",
    "        start, end = bond[\"start_atom\"], bond[\"end_atom\"]\n",
    "        row += [start, end]\n",
    "        col += [end, start]\n",
    "        edge_features += [bond[\"type\"]] * 2\n",
    "\n",
    "    a, e = sparse.edge_index_to_matrix(\n",
    "        edge_index=np.array((row, col)).T,\n",
    "        edge_weight=np.ones_like(row),\n",
    "        edge_features=label_to_one_hot(edge_features, BOND_TYPES),\n",
    "    )\n",
    "    return a, e\n",
    "\n",
    "def read_mol(mol):\n",
    "    x = np.array([atom_to_feature(atom) for atom in mol[\"atoms\"]])\n",
    "    a, e = mol_to_adj(mol)\n",
    "    return x, a, e\n",
    "\n",
    "\n",
    "\n",
    "def parse_sdf(sdf):\n",
    "    #print(sdf)\n",
    "    sdf_out = {}\n",
    "    sdf = sdf.split(\"\\n\")\n",
    "    sdf_out[\"name\"], sdf_out[\"details\"], sdf_out[\"comment\"] = _parse_header(sdf)\n",
    "    sdf_out[\"n_atoms\"], sdf_out[\"n_bonds\"] = _parse_counts_line(sdf)\n",
    "    sdf_out[\"atoms\"] = _parse_atoms_block(sdf, sdf_out[\"n_atoms\"])\n",
    "    sdf_out[\"bonds\"] = _parse_bonds_block(sdf, sdf_out[\"n_atoms\"], sdf_out[\"n_bonds\"])\n",
    "    sdf_out[\"properties\"] = _parse_properties(\n",
    "        sdf, sdf_out[\"n_atoms\"], sdf_out[\"n_bonds\"]\n",
    "    )\n",
    "    sdf_out[\"data\"] = _parse_data_fields(sdf)\n",
    "    return sdf_out\n",
    "\n",
    "def parse_sdf_file(sdf_file, amount=None):\n",
    "    data = sdf_file.read().split(\"$$$$\\n\")\n",
    "    if data[-1] == \"\":\n",
    "        data = data[:-1]\n",
    "    if amount is not None:\n",
    "        data = data[:amount]\n",
    "    output = [parse_sdf(sdf) for sdf in data]  # Parallel execution doesn't help\n",
    "    return output\n",
    "\n",
    "from spektral.utils.io import *\n",
    "\n",
    "def load_sdf(filename, amount=None):\n",
    "    \"\"\"\n",
    "    Load an .sdf file and return a list of molecules in the internal SDF format.\n",
    "    :param filename: target SDF file\n",
    "    :param amount: only load the first `amount` molecules from the file\n",
    "    :return: a list of molecules in the internal SDF format (see documentation).\n",
    "    \"\"\"\n",
    "    #print(\"Reading SDF\")\n",
    "    with open(filename) as f:\n",
    "        return parse_sdf_file(f, amount=amount)\n",
    "\n",
    "\n",
    "\n",
    "class dataset(Dataset):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def read(self):\n",
    "        \n",
    "        names, ret, homo, homo1, diff = sdf()\n",
    "        \n",
    "        mean = np.mean(diff)\n",
    "        std = np.std(diff)\n",
    "        diff_scale = (diff - mean) / std\n",
    "        \n",
    "        mean = np.mean(homo)\n",
    "        std = np.std(homo)\n",
    "        homo_scale = (homo - mean) / std\n",
    "        \n",
    "        \n",
    "        data = [parse_sdf(i) for i in ret]\n",
    "        data = Parallel(n_jobs=-1)(delayed(read_mol)(mol) for mol in tqdm(data, ncols=80))\n",
    "        x_list, a_list, e_list = list(zip(*data))\n",
    "        \n",
    "        dataset = [Graph(x=x, a=a, e=e, y = y) for x, a, e, y \n",
    "                   in zip(x_list, a_list, e_list, homo_scale)]\n",
    "\n",
    "        return dataset\n",
    "\n",
    "dataset = dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_13\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_19 (InputLayer)           [(None, None, 12)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_20 (InputLayer)           [(None, None, None)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_21 (InputLayer)           [(None, None, None,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ecc_conv_12 (ECCConv)           (None, None, 256)    15616       input_19[0][0]                   \n",
      "                                                                 input_20[0][0]                   \n",
      "                                                                 input_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "ecc_conv_13 (ECCConv)           (None, None, 16)     20496       ecc_conv_12[0][0]                \n",
      "                                                                 input_20[0][0]                   \n",
      "                                                                 input_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, None, 100)    1700        ecc_conv_13[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, None, 1)      101         dense_15[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 37,913\n",
      "Trainable params: 37,913\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dataset = graph_dataset\n",
    "################################################################################\n",
    "# PARAMETERS\n",
    "################################################################################\n",
    "learning_rate = 1e-3  # Learning rate\n",
    "epochs = 50  # Number of training epochs\n",
    "batch_size = 1 # Batch size\n",
    "################################################################################\n",
    "# LOAD DATA\n",
    "################################################################################\n",
    "# Train/test split\n",
    "idxs = np.random.permutation(len(dataset))\n",
    "split = int(0.8 * len(dataset))\n",
    "idx_tr, idx_te = np.split(idxs, [split])\n",
    "idx_tr = [int(i) for i in idx_tr]\n",
    "idx_te = [int(i) for i in idx_te]\n",
    "dataset_train = dataset[idx_tr]  \n",
    "dataset_test = dataset[idx_te] \n",
    "\n",
    "\n",
    "# Parameters\n",
    "F = dataset.n_node_features  # Dimension of node features\n",
    "S = dataset.n_edge_features  # Dimension of edge features\n",
    "n_out = dataset.n_labels     # Dimension of the target\n",
    "\n",
    "X_in = Input(shape=(None, F))\n",
    "A_in = Input(shape=(None, None))\n",
    "E_in = Input(shape=(None, None, S))\n",
    "\n",
    "#X_1 = ECCConv(64, activation=\"relu\")([X_in, A_in, E_in])\n",
    "#X_2 = ECCConv(64, activation=\"relu\")([X_1, A_in, E_in])\n",
    "#X_3 = GlobalSumPool()(X_2)\n",
    "#output = Dense(n_out)(X_3)\n",
    "#model = Model(inputs=[X_in, A_in, E_in], outputs=output)\n",
    "#------------------------------------------------------\n",
    "# Parameters\n",
    "\n",
    "\n",
    "X_1 = ECCConv(256, activation=\"relu\")([X_in, A_in, E_in])\n",
    "X_1 = ECCConv(16, activation=\"relu\")([X_1, A_in, E_in])\n",
    "output = Dense(100)(X_1)\n",
    "output = Dense(n_out)(output)\n",
    "model = Model(inputs=[X_in, A_in, E_in], outputs=output)\n",
    "#------------------------------------------------------\n",
    "\n",
    "\n",
    "optimizer = Adam(lr=learning_rate)\n",
    "model.compile(optimizer=optimizer, loss=\"mse\")\n",
    "model.summary()\n",
    "\n",
    "#F = len(ATOM_TYPES)\n",
    "#S = len(BOND_TYPES)\n",
    "n_out = 1\n",
    "\n",
    "steps_per_epoch = len(dataset) /  batch_size\n",
    "loader = BatchLoader(dataset, epochs = epochs, batch_size = batch_size)\n",
    "\n",
    "steps_per_epoch = len(dataset_train) /  batch_size\n",
    "loader_train = BatchLoader(dataset_train, epochs = epochs, batch_size = batch_size)\n",
    "\n",
    "steps_per_epoch = len(dataset_test) /  batch_size\n",
    "loader_test = BatchLoader(dataset_test, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "46546/46546 [==============================] - 93s 2ms/step - loss: 0.8307\n",
      "Epoch 2/50\n",
      "46546/46546 [==============================] - 93s 2ms/step - loss: 0.8042\n",
      "Epoch 3/50\n",
      "46546/46546 [==============================] - 93s 2ms/step - loss: 0.7989\n",
      "Epoch 4/50\n",
      "46546/46546 [==============================] - 93s 2ms/step - loss: 0.7973\n",
      "Epoch 5/50\n",
      "46546/46546 [==============================] - 93s 2ms/step - loss: 0.7959\n",
      "Epoch 6/50\n",
      "46546/46546 [==============================] - 93s 2ms/step - loss: 0.7948\n",
      "Epoch 7/50\n",
      "46546/46546 [==============================] - 93s 2ms/step - loss: 0.7924\n",
      "Epoch 8/50\n",
      "46546/46546 [==============================] - 93s 2ms/step - loss: 0.7902\n",
      "Epoch 9/50\n",
      "46546/46546 [==============================] - 93s 2ms/step - loss: 0.7887\n",
      "Epoch 10/50\n",
      "46546/46546 [==============================] - 93s 2ms/step - loss: 0.7882\n",
      "Epoch 11/50\n",
      "46546/46546 [==============================] - 93s 2ms/step - loss: 0.7876\n",
      "Epoch 12/50\n",
      "46546/46546 [==============================] - 93s 2ms/step - loss: 0.7874\n",
      "Epoch 13/50\n",
      "46546/46546 [==============================] - 93s 2ms/step - loss: 0.7871\n",
      "Epoch 14/50\n",
      "46546/46546 [==============================] - 93s 2ms/step - loss: 0.7872\n",
      "Epoch 15/50\n",
      "46546/46546 [==============================] - 93s 2ms/step - loss: 0.7871\n",
      "Epoch 16/50\n",
      "46546/46546 [==============================] - 95s 2ms/step - loss: 0.7866\n",
      "Epoch 17/50\n",
      "46546/46546 [==============================] - 102s 2ms/step - loss: 0.7869\n",
      "Epoch 18/50\n",
      "46546/46546 [==============================] - 137s 3ms/step - loss: 0.7866\n",
      "Epoch 19/50\n",
      "46546/46546 [==============================] - 107s 2ms/step - loss: 0.7861\n",
      "Epoch 20/50\n",
      "46546/46546 [==============================] - 98s 2ms/step - loss: 0.7863\n",
      "Epoch 21/50\n",
      "46546/46546 [==============================] - 96s 2ms/step - loss: 0.7861\n",
      "Epoch 22/50\n",
      "46546/46546 [==============================] - 96s 2ms/step - loss: 0.7856\n",
      "Epoch 23/50\n",
      "46546/46546 [==============================] - 132s 3ms/step - loss: 0.7853\n",
      "Epoch 24/50\n",
      "46546/46546 [==============================] - 113s 2ms/step - loss: 0.7856\n",
      "Epoch 25/50\n",
      "46546/46546 [==============================] - 99s 2ms/step - loss: 0.7853\n",
      "Epoch 26/50\n",
      "46546/46546 [==============================] - 99s 2ms/step - loss: 0.7850\n",
      "Epoch 27/50\n",
      "46546/46546 [==============================] - 98s 2ms/step - loss: 0.7852\n",
      "Epoch 28/50\n",
      "46546/46546 [==============================] - 127s 3ms/step - loss: 0.7850\n",
      "Epoch 29/50\n",
      "46546/46546 [==============================] - 100s 2ms/step - loss: 0.7851\n",
      "Epoch 30/50\n",
      "46546/46546 [==============================] - 99s 2ms/step - loss: 0.7851\n",
      "Epoch 31/50\n",
      "46546/46546 [==============================] - 132s 3ms/step - loss: 0.7848\n",
      "Epoch 32/50\n",
      "46546/46546 [==============================] - 131s 3ms/step - loss: 0.7849\n",
      "Epoch 33/50\n",
      "46546/46546 [==============================] - ETA: 0s - loss: 0.785 - 104s 2ms/step - loss: 0.7852\n",
      "Epoch 34/50\n",
      "46546/46546 [==============================] - 104s 2ms/step - loss: 0.7847\n",
      "Epoch 35/50\n",
      "46546/46546 [==============================] - 104s 2ms/step - loss: 0.7853\n",
      "Epoch 36/50\n",
      "46546/46546 [==============================] - 103s 2ms/step - loss: 0.7848\n",
      "Epoch 37/50\n",
      "46546/46546 [==============================] - 101s 2ms/step - loss: 0.7851\n",
      "Epoch 38/50\n",
      "46546/46546 [==============================] - 99s 2ms/step - loss: 0.7851\n",
      "Epoch 39/50\n",
      "46546/46546 [==============================] - 137s 3ms/step - loss: 0.7849\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd6446e2f10>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='loss', mode='min', patience = 5)\n",
    "\n",
    "model.fit(loader_train.load(),  steps_per_epoch=loader_train.steps_per_epoch, \n",
    "          epochs = 50, callbacks = [es])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11637/11637 [==============================] - 27s 2ms/step - loss: 0.7877\n",
      "Done. Test loss: 0.7876635193824768\n"
     ]
    }
   ],
   "source": [
    "model_loss = model.evaluate(loader_test.load(), steps=loader_test.steps_per_epoch)\n",
    "print(\"Done. Test loss: {}\".format(model_loss))\n",
    "#y_test = np.array([dataset[i][\"y\"] for i in idx_te])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.213580820406424\n"
     ]
    }
   ],
   "source": [
    "#y_pred = model.predict(loader_test.load(), verbose = 1, steps=loader_test.steps_per_epoch)\n",
    "#model_loss = model.evaluate(loader_test.load(), verbose = 1, steps=loader_test.steps_per_epoch)\n",
    "print(r2_score(y_pred, np.array([dataset[i][\"y\"] for i in idx_te])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.029605182\n",
      "0.91328937\n",
      "[[ 1.2681745 ]\n",
      " [ 0.24829744]\n",
      " [-0.3539981 ]\n",
      " ...\n",
      " [ 1.3477967 ]\n",
      " [-1.5355862 ]\n",
      " [-0.04379122]]\n",
      "[-0.33756345  0.32093089 -0.32329292 ... -0.70457628  0.53356969\n",
      "  2.17050211]\n",
      "-0.0032326487639090054\n",
      "1.001145779008365\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(y_pred))\n",
    "print(np.std(y_pred))\n",
    "print(y_pred)\n",
    "pred =np.array([dataset[i][\"y\"] for i in idx_te])\n",
    "print(pred)\n",
    "print(np.mean(pred))\n",
    "print(np.std(pred))\n",
    "\n",
    "#print(r2_score(y_pred, np.array([dataset[i][\"y\"] for i in idx_te])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-172-a83107573002>, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-172-a83107573002>\"\u001b[0;36m, line \u001b[0;32m18\u001b[0m\n\u001b[0;31m    model.compile(optimizer=\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Parameters\n",
    "F = dataset.n_node_features  # Dimension of node features\n",
    "S = dataset.n_edge_features  # Dimension of edge features\n",
    "n_out = dataset.n_labels     # Dimension of the target\n",
    "\n",
    "X_in = Input(shape=(None, F))\n",
    "A_in = Input(shape=(None, None))\n",
    "E_in = Input(shape=(None, None, S))\n",
    "\n",
    "X_1 = ECCConv(256, activation=\"relu\")([X_in, A_in, E_in])\n",
    "X_2 = ECCConv(256, activation=\"relu\")([X_1, A_in, E_in])\n",
    "X_3 = GlobalSumPool()(X_2)\n",
    "output = Dense(n_out)(X_3)\n",
    "\n",
    "model = Model(inputs=[X_in, A_in, E_in], outputs=output)\n",
    "\n",
    "optimizer = Adam(lr=learning_rate)\n",
    "model.compile(optimizer="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
